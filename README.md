# Let me see

Let me see: an encoder-decoder image captioning 

## Credits

This repository is based on previous work of:

* Vinyals, O. T. (2015). Show and Tell: A neural image Caption generator. arXiv, 1411.4555.
* Tanti, M. G. (2018). Where to put the Image in an Image Caption Generator. arXiv:, 1703.09137.
  
## Author

Jose Ignacio Bengoechea Isasa, ignacio.bengis@gmail.com

## Quickstart

* Language: Python 3.7.
* Requires tensorflow, keras, pillow, numpy, pandas.

Assuming git, python and pip installed:

```bash
 git clone https://github.com/Bengis/Let-me-see
 cd Let-me-see/code
 python preprocessing.py
 python encoder.py
 python train.py
```
## Dataset

The dataset of this software is Flickr8K.
You can request [here](https://forms.illinois.edu/sec/1713398) to download the dataset.

## About this software

* This software is part of the final proyect of the Master of Data Science
* Master of Data Science.
* [Universitat Oberta of Catalunya.](http://www.uoc.edu/portal/ca/index.html)
* Tutored by: Anna Bosch Ru√©

